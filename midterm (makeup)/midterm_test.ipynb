{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f737113e",
   "metadata": {},
   "source": [
    "# ENG286 Midterm Makeup Test\n",
    "\n",
    "### Duration: One hour, fifty minutes\n",
    "\n",
    "### Three Parts, 38 Total Points Possible"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7682bab",
   "metadata": {},
   "source": [
    "# Part 1: Coding Exercises (10 points, ~25 minutes)\n",
    "\n",
    "Part 1 of the exam asks you to perform a variety of coding tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caffccee",
   "metadata": {},
   "source": [
    "### Task 1 (3 points)\n",
    "\n",
    "**Create the following three variables:**\n",
    "\n",
    "- **`string1`: a string with a length between 5 and 10 characters**\n",
    "- **`string2`: another string with a length between 10 and 20 characters**\n",
    "- **`integer`: an integer between 2 and 5**\n",
    "\n",
    "You may wish to verify your work by running `print()` on each of your newly created variables, and using `type()` to verify the type of each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c791edb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad73fafc",
   "metadata": {},
   "source": [
    "### Task 2 (3 points)\n",
    "\n",
    "**Create the following three variables:**\n",
    "\n",
    "* **Make `string3` by multiplying `string1` by `integer`**\n",
    "* **Make `string4` by adding `string1` and `string2` together**\n",
    "* **Make `boolean` by testing whether `string3` is equal to `string4`**\n",
    "\n",
    "You may wish to verify your work by running `print()` and `type()` on each of these newly created variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5391d13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c158746",
   "metadata": {},
   "source": [
    "### Task 3 (2 points)\n",
    "\n",
    "**Create a new list variable, `list_o_strings`, which contains the values (in order) of `string1`, `string2`, `string3`, and `string4`.**\n",
    "\n",
    "You may wish to verify your work by running `print()` on `list_o_strings`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1694b35b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ff4dc7e",
   "metadata": {},
   "source": [
    "### Task 4 (2 points)\n",
    "\n",
    "**Create a variable named `len_of_strings` that refers to an empty list. Using a `for` loop, iterate through the items in `list_o_strings`, finding the length (in number of characters) of each of the strings and adding these lengths, one by one, to the `len_of_strings` variable.**\n",
    "\n",
    "You may wish to verify your work by running `print()` on `len_of_strings`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e887ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "405167cf",
   "metadata": {},
   "source": [
    "# Part 2: Type-Token Ratios (18 points, ~45 minutes)\n",
    "\n",
    "Part 2 of this exam consists of a TTR experiment on the chapters of Sir Arthur Conan Doyle's *The Sign of the Four*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b064b425",
   "metadata": {},
   "source": [
    "The code cell below calculates non-standardized and standardized Type-Token Ratios for each of the chapters in *The Sign of the Four*.\n",
    "\n",
    "Run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "98538980",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "folder_path = \"sot4chaps/\"\n",
    "\n",
    "sample_size = 0\n",
    "\n",
    "file = open(\"ttr-overall.csv\", mode=\"w\", encoding=\"utf-8\")\n",
    "\n",
    "file.write('\"Text\",\"Types\",\"Tokens\",\"TTR\"\\n')\n",
    "\n",
    "for file_path in sorted(Path(folder_path).glob('*.txt')):\n",
    "    \n",
    "    text = open(file_path, encoding='utf-8').read()\n",
    "    text = re.sub(\"[^a-zA-Z0-9]\", \" \", text)\n",
    "    \n",
    "    text_words = text.split()\n",
    "    tokens = len(text_words)  \n",
    "    \n",
    "    if sample_size == 0 or tokens < sample_size:\n",
    "        sample_size = tokens\n",
    "    \n",
    "    unique_words = []\n",
    "    \n",
    "    for word in text_words:\n",
    "        word = word.lower()  \n",
    "        if word not in unique_words:\n",
    "            unique_words.append(word)\n",
    "            \n",
    "    types = len(unique_words)\n",
    "    \n",
    "    ttr = (types / tokens) * 100\n",
    "    \n",
    "    file.write(f'\"{file_path.stem}\",{types},{tokens},{ttr}\\n')\n",
    "\n",
    "file.close()\n",
    "\n",
    "\n",
    "\n",
    "file = open(\"ttr-standardized.csv\", mode=\"w\", encoding=\"utf-8\")\n",
    "\n",
    "file.write('\"Text\",\"Types\",\"Tokens\",\"TTR\"\\n')\n",
    "\n",
    "for file_path in sorted(Path(folder_path).glob('*.txt')):\n",
    "    text = open(file_path, encoding='utf-8').read()\n",
    "    text = re.sub(\"[^a-zA-Z0-9]\", \" \", text)\n",
    "    \n",
    "    text_words = text.split()\n",
    "    text_words_standardized = text_words[:sample_size]\n",
    "    tokens_standardized = len(text_words_standardized)\n",
    "\n",
    "    unique_words_standardized = []\n",
    "    \n",
    "    for word in text_words_standardized:\n",
    "        word = word.lower()\n",
    "        if word not in unique_words_standardized:\n",
    "            unique_words_standardized.append(word)\n",
    "            \n",
    "    types_standardized = len(unique_words_standardized)\n",
    "    \n",
    "    ttr_standardized = (types_standardized / tokens_standardized) * 100\n",
    "    \n",
    "    file.write(f'\"{file_path.stem}\",{types_standardized},{tokens_standardized},{ttr_standardized}\\n')\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427a0052",
   "metadata": {},
   "source": [
    "## Tasks 6-8: Code Rationale\n",
    "\n",
    "This section consists of short answer questions relating to the code used above to calculate non-standardized and standardized TTRs for the chapters of *The Sign of the Four*.\n",
    "\n",
    "### Task 6 (3 points)\n",
    "\n",
    "**Why do we lowercase all words when calculating the number of types in a text? How would our TTR results be different if we didn't lowercase all words during this step?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e63604",
   "metadata": {},
   "source": [
    "(**REPLACE THIS TEXT AND ENTER YOUR ANSWER HERE.**)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abdf442",
   "metadata": {},
   "source": [
    "### Task 7 (3 points)\n",
    "\n",
    "**Why do we need to remove punctuation from the text in order to accurately determine the number of types and tokens in the text? How would our TTR results be different if we didn't remove punctuation?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324d7564",
   "metadata": {},
   "source": [
    "(**REPLACE THIS TEXT AND ENTER YOUR ANSWER HERE.**)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee378d1",
   "metadata": {},
   "source": [
    "### Task 8 (3 points)\n",
    "\n",
    "**In the line of code `text = re.sub(\"[^a-zA-Z0-9]\", \" \", text)`, what does the regular expression `[^a-zA-Z9-0]` mean? How would it affect our TTR values if we instead wrote `[a-zA-Z0-9]`, so that the line of code was `text = re.sub(\"[a-zA-Z0-9]\", \" \", text)`?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442eec30",
   "metadata": {},
   "source": [
    "(**REPLACE THIS TEXT AND ENTER YOUR ANSWER HERE.**)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75404f5d",
   "metadata": {},
   "source": [
    "The two code cells below load the CSV files created above and display them as tables. \n",
    "\n",
    "The first cell gives non-standardized values, and the second gives standardized values.\n",
    "\n",
    "Run both cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "081ca137",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'ttr-overall.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m \n\u001b[1;32m----> 2\u001b[0m sot4chaps_overall \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mttr-overall.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m sot4chaps_overall\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ttr-overall.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "sot4chaps_overall = pd.read_csv('ttr-overall.csv')\n",
    "sot4chaps_overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69a7fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sot4chaps_standardized = pd.read_csv('ttr-standardized.csv')\n",
    "sot4chaps_standardized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e58365",
   "metadata": {},
   "source": [
    "## Tasks 9â€“11: TTR Interpretation\n",
    "\n",
    "This section asks questions related to the results of the TTR experiment, displayed in the tables above.\n",
    "\n",
    "### Task 9 (3 points)\n",
    "\n",
    "**What might you learn from an experiment like this, which compares the TTRs of various parts of a single work? Why make this kind of comparison?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65617c24",
   "metadata": {},
   "source": [
    "(**REPLACE THIS TEXT AND ENTER YOUR ANSWER HERE.**)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6754a9",
   "metadata": {},
   "source": [
    "### Task 10 (3 points)\n",
    "\n",
    "**What do we actually learn from this particular TTR experiment? Which numbers strike you as the most significant?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943b7064",
   "metadata": {},
   "source": [
    "(**REPLACE THIS TEXT AND ENTER YOUR ANSWER HERE.**)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5e0c69",
   "metadata": {},
   "source": [
    "### Task 11 (3 points)\n",
    "\n",
    "**What further data or information would you require to interpret these numbers more fully?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9ff674",
   "metadata": {},
   "source": [
    "(**REPLACE THIS TEXT AND ENTER YOUR ANSWER HERE.**)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e8a5bf",
   "metadata": {},
   "source": [
    "# Part 3: Reading Response (10 points, ~25 minutes) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2d5832",
   "metadata": {},
   "source": [
    "In our first lecture, we discussed the question of whether Sherlock Holmes is \"the most objective character in *The Sign of the Four*.\" \n",
    "\n",
    "In the course of this discussion, we met the subjectivity score system that comes as part of the TextBlob package. The system automatically assigns a score between 0.0 (not at all subjective) and 1.0 (extremely subjective) to any string. \n",
    "\n",
    "We then looked at the following table. It shows a sorted list of all the characters in *The Sign of the Four*, ranked in terms of the average \"subjectivity\" of their passages of dialogue in the novel. The characters whose speech is deemed \"most subjective\" (and \"least objective\") appear at the bottom of the list.\n",
    "\n",
    "![Table of characters in The Sign of the Four, ranked by mean subjectivity](mean_subjectivity_sot4.png)\n",
    "\n",
    "We concluded our discussion by asking whether TextBlob's subjectivity score can itself be considered \"objective.\" In particular, we asked \"What would we need to know to answer that question?\"\n",
    "\n",
    "Many of the course readings since that first lecture have addressed these kinds of questions directly. \n",
    "\n",
    "### Task 12 (10 points)\n",
    "\n",
    "**Drawing on AT LEAST ONE COURSE READING, present your current response to that question. What would we need to know in order to assess whether TextBlob's subjectivity score is itself \"objective\"?**\n",
    "\n",
    "In the Markdown cell below, provide a well-organized response of 1-2 paragraphs. You should write in complete sentences (i.e., not point form). You will be graded on the quality of your response rather than the length.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fba880c",
   "metadata": {},
   "source": [
    "(**REPLACE THIS TEXT AND ENTER YOUR ANSWER HERE.**)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465c7ba8",
   "metadata": {},
   "source": [
    "## How to Submit\n",
    "1. Download your midterm Jupyter notebook to your local computer and save it as `midterm_test.ipynb`.\n",
    "2. Log in here: https://markus-ds.teach.cs.toronto.edu.\n",
    "3. Submit your notebook to `midterm (makeup)`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "901b79e026e03396fd1ffa7133844e9ea80e258ce34c66e1aabb5896bcb18463"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
